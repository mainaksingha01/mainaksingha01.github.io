<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Publications</title>
</head>

<!-- Popup CSS -->
<style type="text/css">
.bib-popup {
  display: none;
  position: fixed;
  z-index: 9999;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: rgba(0,0,0,0.55);
}

.bib-popup-content {
  background: #fff;
  width: 100%;
  max-width: 1200px;
  margin: 10% auto;
  padding: 20px;
  border-radius: 8px;
  font-family: monospace;
  font-size: 14px;
  white-space: pre-wrap;
  border: 1px solid #999;
}

.bib-close {
  float: right;
  font-size: 22px;
  cursor: pointer;
  margin-top: -10px;
}
</style>

<!-- Popup Container -->
<div id="bib-popup" class="bib-popup">
  <div class="bib-popup-content">
    <span id="bib-close" class="bib-close">&#10006;</span>
    <pre id="bib-text"></pre>
  </div>
</div>

<!-- XHTML-Safe JavaScript -->
<script type="text/javascript">
// <![CDATA[
document.addEventListener("DOMContentLoaded", function () {
    var popup = document.getElementById("bib-popup");
    var bibText = document.getElementById("bib-text");
    var closeBtn = document.getElementById("bib-close");

    // Attach to all .bib-btn links
    var buttons = document.getElementsByClassName("bib-btn");

    for (var i = 0; i < buttons.length; i++) {
        buttons[i].addEventListener("click", function (e) {
            e.preventDefault();
            var target = this.getAttribute("data-target");
            var bib = document.getElementById(target);
            bibText.textContent = bib.textContent;
            popup.style.display = "block";
        });
    }

    closeBtn.addEventListener("click", function () {
        popup.style.display = "none";
    });

    popup.addEventListener("click", function (event) {
        if (event.target === popup) {
            popup.style.display = "none";
        }
    });

    document.addEventListener("keydown", function(event){
        if (event.key === "Escape") {
            popup.style.display = "none";
        }
    });
});
// ]]>
</script>

<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Mainak Singha</div>
<div class="menu-item"><a href="./index.html">Home</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="./publications.html" class="current">Publications</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publications</h1>
</div>
<h2>Preprints <br /> <br /></h2>

<ol>

<li>
<p>
<b>How (Mis)calibrated is Your Federated CLIP and What To Do About It?</b> <br />
<span style="color:#527bbd; font-weight:bold;">Mainak Singha</span>, Masih Aminbeidokhti, Paolo Casari, Elisa Ricci, Subhankar Roy <br />
<i>arXiv Preprint, 2025.</i>
<br />
<span style="margin-left:20px;">
[ <a href="https://arxiv.org/pdf/2512.04305" target="_blank">arXiv</a> ] &nbsp;
[ <a href="https://github.com/mainaksingha01/FL2oRA" target="_blank">Code</a> ]
</span>
</p>
</li>

</ol>

<h2>Conferences <br /> <br /></h2>
<ol>

<li>
<p>
<b>FedMVP: Federated Multi-modal Visual Prompt Tuning for Vision-Language Models</b> <br />
<span style="color:#527bbd; font-weight:bold;">Mainak Singha</span>, Subhankar Roy, Sarthak Mehrotra, Ankit Jha, Moloud Abdar, Biplab Banerjee, Elisa Ricci <br />
<i>International Conference on Computer Vision (ICCV), 2025.</i>
<br />
<span style="margin-left:20px;">
[ <a href="https://openaccess.thecvf.com/content/ICCV2025/papers/Singha_FedMVP_Federated_Multimodal_Visual_Prompt_Tuning_for_Vision-Language_Models_ICCV_2025_paper.pdf" target="_blank">PDF</a> ] &nbsp;
[ <a href="https://arxiv.org/pdf/2504.20860" target="_blank">arXiv</a> ] &nbsp;
[ <a href="https://github.com/mainaksingha01/FedMVP" target="_blank">Code</a> ] &nbsp;
[ <a href="https://openaccess.thecvf.com/content/ICCV2025/html/Singha_FedMVP_Federated_Multimodal_Visual_Prompt_Tuning_for_Vision-Language_Models_ICCV_2025_paper.html" target="_blank">HTML</a> ] &nbsp;
[ <a href="#" class="bib-btn" data-target="bib-fedmvp">BibTeX</a> ]
</span>

<pre id="bib-fedmvp" class="bibtex-block" style="display:none;">
@article{fedmvp,
  title={FedMVP: Federated Multi-modal Visual Prompt Tuning for Vision-Language Models},
  author={Singha, Mainak and Roy, Subhankar and Mehrotra, Sarthak and Jha, Ankit and Abdar, Moloud and Banerjee, Biplab and Ricci, Elisa},
  journal={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year={2025}
}
</pre>
</p>
</li>

<li>
<p>
<b>OSLoPrompt: Bridging Low-Supervision Challenges and Open-Set Domain Generalization in CLIP</b> <br />
Mohamad Hassan N C, Divyam Gupta, <span style="color:#527bbd; font-weight:bold;">Mainak Singha</span>, Sai Bhargav Rongali, Ankit Jha, Muhammad Haris Khan, Biplab Banerjee <br />
<i>Computer Vision and Pattern Recognition Conference (CVPR), 2025.</i>
<br />
<span style="margin-left:20px;">
[ <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/C_OSLoPrompt_Bridging_Low-Supervision_Challenges_and_Open-Set_Domain_Generalization_in_CLIP_CVPR_2025_paper.pdf" target="_blank">PDF</a> ] &nbsp;
[ <a href="https://arxiv.org/pdf/2503.16106" target="_blank">arXiv</a> ] &nbsp;
[ <a href="https://github.com/has97/osloprompt" target="_blank">Code</a> ] &nbsp;
[ <a href="https://openaccess.thecvf.com/content/CVPR2025/html/C_OSLoPrompt_Bridging_Low-Supervision_Challenges_and_Open-Set_Domain_Generalization_in_CLIP_CVPR_2025_paper.html" target="_blank">HTML</a> ] &nbsp;
[ <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:_QDhkj76iS4J:scholar.google.com/&output=citation&scisdr=CrylxrZLELHTl_WkOmk:ALhkC2QAAAAAaTKiImkkx8V5Zncz6pcHtX9GOWY&scisig=ALhkC2QAAAAAaTKiInQw8uFIk35bPXg9qK6p3WM&scisf=4&ct=citation&cd=-1&hl=en&scfhb=1" target="_blank">BibTeX</a> ]
</span>
</p>
</li>

<li>
<p>
<b>Elevating <i>All</i> Zero-Shot Sketch-Based Image Retrieval Through Multimodal Prompt Learning</b> <br />
<span style="color:#527bbd; font-weight:bold;">Mainak Singha</span>, Ankit Jha, Divyam Gupta, Pranav Singla, Biplab Banerjee <br />
<i>European Conference on Computer Vision (ECCV), 2024.</i>
<br />
<span style="margin-left:20px;">
[ <a href="https://link.springer.com/chapter/10.1007/978-3-031-72691-0_1">PDF</a> ] &nbsp;
[ <a href="https://arxiv.org/pdf/2407.04207" target="_blank">arXiv</a> ] &nbsp;
[ <a href="https://github.com/mainaksingha01/SpLIP" target="_blank">Code</a> ] &nbsp;
[ <a href="https://mainaksingha01.github.io/SpLIP/" target="_blank">Project</a> ] &nbsp;
[ <a href="https://link.springer.com/chapter/10.1007/978-3-031-72691-0_1" target="_blank">HTML</a> ] &nbsp;
[ <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:7d35ylLiE1EJ:scholar.google.com/&output=citation&scisdr=CrylxrZLELHTl_Wn954:ALhkC2QAAAAAaTKh757PFVg2S7b8xDsQ0lBJ3XQ&scisig=ALhkC2QAAAAAaTKh7yRKxj8OmphnrrOVs0TmJ6w&scisf=4&ct=citation&cd=-1&hl=en&scfhb=1" target="_blank">BibTeX</a> ]
</span>
</p>
</li>

<li>
<p>
<b>COSMo: CLIP Talks on Open-Set Multi-Target Domain Adaptation</b> <br />
Munish Monga, Sachin Kumar Giroh, Ankit Jha, <span style="color:#527bbd; font-weight:bold;">Mainak Singha</span>, Biplab Banerjee, Jocelyn Chanussot<br />
<i>British Machine Vision Conference (BMVC), 2024.</i>
<br />
<span style="margin-left:20px;">
[ <a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_31/paper.pdf" target="_blank">PDF</a> ] &nbsp;
[ <a href="https://arxiv.org/pdf/2409.00397" target="_blank">arXiv</a> ] &nbsp;
[ <a href="https://github.com/munish30monga/COSMo" target="_blank">Code</a> ] &nbsp;
[ <a href="https://bmvc2024.org/proceedings/31/" target="_blank">HTML</a> ] &nbsp;
[ <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:USDB0PyAelQJ:scholar.google.com/&output=citation&scisdr=CrylxrZLELHTl_Wv7HE:ALhkC2QAAAAAaTKp9HFe7PL10O4_kQC5O9WsK7U&scisig=ALhkC2QAAAAAaTKp9DG0C9ZLJYF8I_o8Ltz21ng&scisf=4&ct=citation&cd=-1&hl=en&scfhb=1" target="_blank">BibTeX</a> ] 
</span>
</p>
</li>


<li>
<p>
<b>Unknown Prompt, the only Lacuna: Unveiling CLIPâ€™s Potential for Open Domain Generalization</b> <br />
<span style="color:#527bbd; font-weight:bold;">Mainak Singha</span>, Ankit Jha, Shirsha Bose, Ashwin Nair, Moloud Abdar, Biplab Banerjee<br />
<i>Computer Vision and Pattern Recognition Conference (CVPR), 2024.</i>
<br />
<span style="margin-left:20px;">
[ <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Singha_Unknown_Prompt_the_only_Lacuna_Unveiling_CLIPs_Potential_for_Open_CVPR_2024_paper.pdf" target="_blank">PDF</a> ] &nbsp;
[ <a href="https://arxiv.org/pdf/2404.00710" target="_blank">arXiv</a> ] &nbsp;
[ <a href="https://github.com/mainaksingha01/ODG-CLIP" target="_blank">Code</a> ] &nbsp;
[ <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Singha_Unknown_Prompt_the_only_Lacuna_Unveiling_CLIPs_Potential_for_Open_CVPR_2024_paper.html" target="_blank">HTML</a> ] &nbsp;
[ <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:HS3-ueGbvZ0J:scholar.google.com/&output=citation&scisdr=CrylxrZLELHTl_Wijwo:ALhkC2QAAAAAaTKklwrkzf_I5i6rZ4YK3HZaUBw&scisig=ALhkC2QAAAAAaTKkl9luBsBvqD303jZMpg6bOaM&scisf=4&ct=citation&cd=-1&hl=en&scfhb=1" target="_blank">BibTeX</a> ] 
</span>
</p>
</li>


<li>
<p>
<b>CDAD-Net: Bridging Domain Gaps in Generalized Category Discovery</b> <br />
Sai Bhargav Rongali, Sarthak Mehrotra, Ankit Jha, Mohamad Hassan N C, Shirsha Bose, Tanisha Gupta, <span style="color:#527bbd; font-weight:bold;">Mainak Singha</span>, Biplab Banerjee<br />
<i>Computer Vision and Pattern Recognition Conference (CVPR) Workshops, 2024.</i>
<br />
<span style="margin-left:20px;">
[ <a href="https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/papers/Rongali_CDAD-Net_Bridging_Domain_Gaps_in_Generalized_Category_Discovery_CVPRW_2024_paper.pdf" target="_blank">PDF</a> ] &nbsp;
[ <a href="https://arxiv.org/pdf/2404.05366" target="_blank">arXiv</a> ] &nbsp;
[ <a href="https://github.com/SarthakM320/CDAD-Net" target="_blank">Code</a> ] &nbsp;
[ <a href="https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/html/Rongali_CDAD-Net_Bridging_Domain_Gaps_in_Generalized_Category_Discovery_CVPRW_2024_paper.html" target="_blank">HTML</a> ] &nbsp;
[ <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:x5e1vXoxJ8YJ:scholar.google.com/&output=citation&scisdr=CrylxrZLELHTl_WtOCA:ALhkC2QAAAAAaTKrICCsLH7XGj7SZUaOdI5jBG4&scisig=ALhkC2QAAAAAaTKrIO1e1Bfyp7u2drlOERjZzxg&scisf=4&ct=citation&cd=-1&hl=en&scfhb=1" target="_blank">BibTeX</a> ] 
</span>
</p>
</li>


<li>
<p>
<b>GraphVL: Graph-Enhanced Semantic Modeling via Vision-Language Models for Generalized Class Discovery</b> <br />
Bhupendra Solanki, Ashwin R Nair, <span style="color:#527bbd; font-weight:bold;">Mainak Singha</span>, Souradeep Mukhopadhyay, Ankit Jha, Biplab Banerjee<br />
<i>Indian Conference on Computer Vision Graphics and Image Processing (ICVGIP), 2024.</i>
<br />
<span style="margin-left:20px;">
[ <a href="https://dl.acm.org/doi/pdf/10.1145/3702250.3702266" target="_blank">PDF</a> ] &nbsp;
[ <a href="https://arxiv.org/pdf/2411.02074" target="_blank">arXiv</a> ] &nbsp;
[ <a href="https://dl.acm.org/doi/full/10.1145/3702250.3702266" target="_blank">HTML</a> ] &nbsp;
[ <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:1BKLn8GFgssJ:scholar.google.com/&output=citation&scisdr=CrylxrZLELHTl_Jxmwk:ALhkC2QAAAAAaTV3gwlsKKJOwD4DwV673OP9iPA&scisig=ALhkC2QAAAAAaTV3gzACJjQoGUl7ErdG2CzUPv8&scisf=4&ct=citation&cd=-1&hl=en&scfhb=1" target="_blank">BibTeX</a> ] 
</span>
</p>
</li>


<li>
<p>
<b>StyLIP: Multi-Scale Style-Conditioned Prompt Learning for CLIP-based Domain Generalization</b> <br />
Shirsha Bose, Ankit Jha, Enrico Fini, <span style="color:#527bbd; font-weight:bold;">Mainak Singha</span>, Biplab Banerjee, Elisa Ricci<br />
<i>Winter Conference on Applications of Computer Vision (WACV), 2024.</i>
<br />
<span style="margin-left:20px;">
[ <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Bose_STYLIP_Multi-Scale_Style-Conditioned_Prompt_Learning_for_CLIP-Based_Domain_Generalization_WACV_2024_paper.pdf" target="_blank">PDF</a> ] &nbsp;
[ <a href="https://arxiv.org/pdf/2302.09251" target="_blank">arXiv</a> ] &nbsp;
[ <a href="https://openaccess.thecvf.com/content/WACV2024/html/Bose_STYLIP_Multi-Scale_Style-Conditioned_Prompt_Learning_for_CLIP-Based_Domain_Generalization_WACV_2024_paper.html" target="_blank">HTML</a> ] &nbsp;
[ <a href="#" class="bib-btn" data-target="bib-stylip">BibTeX</a> ]
</span>

<pre id="bib-stylip" class="bibtex-block" style="display:none;">
@inproceedings{bose2024stylip,
  title={Stylip: Multi-scale style-conditioned prompt learning for clip-based domain generalization},
  author={Bose, Shirsha and Jha, Ankit and Fini, Enrico and Singha, Mainak and Ricci, Elisa and Banerjee, Biplab},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={5542--5552},
  year={2024}
}
</pre>
</p>
</li>
  
</ol>


<h2>Journals <br /> <br /></h2>

<ol>

<li>
<p>
<b>Meta-Learning to Teach Semantic Prompts for Open Domain Generalization in Vision-Language Models</b> <br />
Shirsha Bose, <span style="color:#527bbd; font-weight:bold;">Mainak Singha</span>, Ankit Jha, Souradeep Mukhopadhyay, Biplab Banerjee <br />
<i>Transactions on Machine Learning Research (TMLR), 2025.</i>
<br />
<span style="margin-left:20px;">
[ <a href="https://openreview.net/pdf?id=uJELgNGiMW" target="_blank">PDF</a> ] &nbsp;
[ <a href="https://openreview.net/forum?id=uJELgNGiMW" target="_blank">HTML</a> ] &nbsp;
[ <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:4qmg90Pwi2EJ:scholar.google.com/&output=citation&scisdr=CrylxrZLELHTl_WkY0I:ALhkC2QAAAAAaTKie0LBjzhjDzPpKcaGPQMakCY&scisig=ALhkC2QAAAAAaTKie1jMfIDcfhpSRoj9dgJfK9M&scisf=4&ct=citation&cd=-1&hl=en" target="_blank">BibTeX</a> ]
</span>
</p>
</li>


<li>
<p>
<b>RS<sup>3</sup>Lip: Consistency for remote sensing image classification on part embeddings using self-supervised learning and CLIP</b> <br />
Ankit Jha, <span style="color:#527bbd; font-weight:bold;">Mainak Singha</span>, Avigyan Bhattacharya, Biplab Banerjee <br />
<i>Computer Vision and Image Understanding (CVIU), 2025.</i>
<br />
<span style="margin-left:20px;">
[ <a href="https://pdf.sciencedirectassets.com/271018/1-s2.0-S1077314224X00120/1-s2.0-S1077314224003357/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEMT%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIC1zhvo4vtoN1Ui2Dd6whqbvNYH23Qp4K0FhMDwryCPsAiBE8jfcRaj7stiX1fwBYZp6hZTdbVbN5VtXy5lx%2BohciSq7BQiN%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAUaDDA1OTAwMzU0Njg2NSIMQFxe69%2BVIQhPxrL%2BKo8Fnd9dT0SVx1E7Sxi1u7kNugHNSGoomdyYJA%2F47hNopobvw9vXzJDOJWds1g5J9nR8y1jnGbIfobz7hQzlyleB27aCh886bB%2B54I5wmseaxqSc%2BDryY3mpsDwkF%2FnX1sLfaEdzP%2Bfy7MQ4ok1Memk59nQZxccJ6BhvHsGR2g2l344uR5YGN8RO4Gw%2F%2BbqF%2FtfXBMcehSh4u6O7BFa8BhwI0M5C5tearVFAwDfIK5oY5CjFxo34zfGlr1HAoY%2F4Piz32ZXDP28MW3xtVgeiJuSjr88zt7NFFlFKGJz%2BZn49khPz0UvxbtpNX6hjPxFPLGTAitWArppzuH369cRmTMF0eDCgmfmWWJbRQN8Ihry5pYHA5RIG%2FHIqaL8l%2F8Dfr6OWF%2F1dQbHuVjlgXa6rPaIoB2lxJI9yZ6aWOA%2BCp5cBYjA77uxadm0VlFpJmmvpPBmEpEVGS5%2F8OZtFoS%2FvQLhZXtW4IV7TnVrmRC0TMUtclT3lkDr6NrSUvzfd4ePP1gzVubLnlnmFyRZV67RgACm0zf4ObCeGVs2eQpi23aTypVKjnhbgFBxJPdXU1WGGxDdi9NRlbA%2BanjLDn9axaVUvPs81iHHxOSxaOvhKX6Py6Gv3QNCNuypfYx%2B%2B1phrc2pO5Nijpnf8UrMFp7EU0fovLSHiYjoR9FA5LQmoDaQ96g%2FMTCIEZTgL3Wx3ReyGqifT03Ym4clGXf2W56yUzzUs1IuJS%2Fk5OikUHzOsUom%2B5cIdXnBLgjZ6mXwXctTeRqyFf6dlPeSDyEV%2BIJkMRf8VS64RqPJrXBH%2FSwBzUiuRFBAItY%2B%2FjrUhTWiAHP8k9HcFshX99ws2pTpLDlTqLd4HK9nnGHuHYDtMPCGuLlFL5TDh0dXJBjqyAS%2B8SHYNeH2tJk6cDwmrN9Y91y%2BaRpJ72sx2%2BvcDpb19Cxwg5w%2F5Q8oUl7RWXgxBBxjxeq5cYerG84ogBk9ahyK1KTcvjkrqGw6pUjnCOJZ894mmXXYnkUabgt0zn%2F7Pa%2BcudI1iwKy3qlpO8w7tTjCNPRxWrRb7%2F9Z4AcooC2foz%2FOucYEc5Y4DllZo3b%2BqUhez2ZJTgKq%2FlfPns9FdNft%2Fdkxt6Y95AhtiBiOoWYbBDWo%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251207T125821Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYROHZXKMI%2F20251207%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=bb48abff24384283aacca765839b1d0ed49e0959b413f52420a630a47b3f9281&hash=b0e16633d7a81e1c2de6ae09656b512f9de01ba8537438f9c63e9ea0272d71f0&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1077314224003357&tid=spdf-32cd0285-8b86-4b2c-b053-639201f3276b&sid=a9adb0b76a5d45481c3a213137fed96e8482gxrqb&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=0f12560207545651050b&rr=9aa431add958f349&cc=it" target="_blank">PDF</a> ] &nbsp;
[ <a href="https://www.sciencedirect.com/science/article/pii/S1077314224003357" target="_blank">HTML</a> ] &nbsp;
[ <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:qJg4eUu1wpoJ:scholar.google.com/&output=citation&scisdr=CrylxrZLELHTl_J6eW4:ALhkC2QAAAAAaTV8YW7XKnIRgPMgToFXDUrhUQM&scisig=ALhkC2QAAAAAaTV8YZsigDJ_JQRhea8F3uFu45Y&scisf=4&ct=citation&cd=-1&hl=en&scfhb=1" target="_blank">BibTeX</a> ]
</span>
</p>
</li>

</ol>
 
<div id="footer">
<div id="footer-text">
Page generated 2025-12-04 14:25:00 CET, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
<!-- This script will be injected in the pages of the site to collect visiting info fpr Google analytics.-->
<!-- Use your GoogleAnalytics ID, update the following code and the MY_ID with yours (used two times.)  -->
<script async src="https://www.googletagmanager.com/gtag/js?id=MY_ID"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'MY_ID');
</script>
</body>
</html>

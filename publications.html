<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Publications</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Mainak Singha</div>
<div class="menu-item"><a href="./index.html">Home</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="./publications.html" class="current">Publications</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publications</h1>
</div>
<h2>Preprints <br /> <br /></h2>

<ol>

<li>
<p>
<b>How (Mis)calibrated is Your Federated CLIP and What To Do About It?</b> <br />
<span style="color:#527bbd; font-weight:bold;">Mainak Singha</span>, Masih Aminbeidokhti, Paolo Casari, Elisa Ricci, Subhankar Roy <br />
<i>arXiv Preprint, 2025.</i>
<br />
<span style="margin-left:20px;">
[ <a href="https://arxiv.org/pdf/2512.04305" target="_blank">arXiv</a> ] &nbsp;
[ <a href="https://github.com/mainaksingha01/FL2oRA" target="_blank">Code</a> ]
</span>
</p>
</li>

</ol>

<h2>Conferences <br /> <br /></h2>
<ol>

<li>
<p>
<b>FedMVP: Federated Multi-modal Visual Prompt Tuning for Vision-Language Models</b> <br />
<span style="color:#527bbd; font-weight:bold;">Mainak Singha</span>, Subhankar Roy, Sarthak Mehrotra, Ankit Jha, Moloud Abdar, Biplab Banerjee, Elisa Ricci <br />
<i>International Conference on Computer Vision (ICCV), 2025.</i>
<br />
<span style="margin-left:20px;">
[ <a href="https://openaccess.thecvf.com/content/ICCV2025/papers/Singha_FedMVP_Federated_Multimodal_Visual_Prompt_Tuning_for_Vision-Language_Models_ICCV_2025_paper.pdf" target="_blank">PDF</a> ] &nbsp;
[ <a href="https://arxiv.org/pdf/2504.20860" target="_blank">arXiv</a> ] &nbsp;
[ <a href="https://github.com/mainaksingha01/FedMVP" target="_blank">Code</a> ] &nbsp;
[ <a href="https://openaccess.thecvf.com/content/ICCV2025/html/Singha_FedMVP_Federated_Multimodal_Visual_Prompt_Tuning_for_Vision-Language_Models_ICCV_2025_paper.html" target="_blank">HTML</a> ] &nbsp;
[ <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:Z27VYN5uytoJ:scholar.google.com/&output=citation&scisdr=CrylxrZLELHTl_Wm9eg:ALhkC2QAAAAAaTKg7ejCW_dkIgQGg3y_9FL5Qgk&scisig=ALhkC2QAAAAAaTKg7ftvu_RGih6EwGmKJzcRPgs&scisf=4&ct=citation&cd=-1&hl=en&scfhb=1" target="_blank">BibTeX</a> ] 
</span>
</p>
</li>

<li>
<p>
<b>OSLoPrompt: Bridging Low-Supervision Challenges and Open-Set Domain Generalization in CLIP</b> <br />
Mohamad Hassan N C, Divyam Gupta, <span style="color:#527bbd; font-weight:bold;">Mainak Singha</span>, Sai Bhargav Rongali, Ankit Jha, Muhammad Haris Khan, Biplab Banerjee <br />
<i>Computer Vision and Pattern Recognition Conference (CVPR), 2025.</i>
<br />
<span style="margin-left:20px;">
[ <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/C_OSLoPrompt_Bridging_Low-Supervision_Challenges_and_Open-Set_Domain_Generalization_in_CLIP_CVPR_2025_paper.pdf" target="_blank">PDF</a> ] &nbsp;
[ <a href="https://arxiv.org/pdf/2503.16106" target="_blank">arXiv</a> ] &nbsp;
[ <a href="https://github.com/has97/osloprompt" target="_blank">Code</a> ] &nbsp;
[ <a href="https://openaccess.thecvf.com/content/CVPR2025/html/C_OSLoPrompt_Bridging_Low-Supervision_Challenges_and_Open-Set_Domain_Generalization_in_CLIP_CVPR_2025_paper.html" target="_blank">HTML</a> ] &nbsp;
[ <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:_QDhkj76iS4J:scholar.google.com/&output=citation&scisdr=CrylxrZLELHTl_WkOmk:ALhkC2QAAAAAaTKiImkkx8V5Zncz6pcHtX9GOWY&scisig=ALhkC2QAAAAAaTKiInQw8uFIk35bPXg9qK6p3WM&scisf=4&ct=citation&cd=-1&hl=en&scfhb=1" target="_blank">BibTeX</a> ]
</span>
</p>
</li>

<li>
<p>
<b>Elevating <i>All</i> Zero-Shot Sketch-Based Image Retrieval Through Multimodal Prompt Learning</b> <br />
<span style="color:#527bbd; font-weight:bold;">Mainak Singha</span>, Ankit Jha, Divyam Gupta, Pranav Singla, Biplab Banerjee <br />
<i>European Conference on Computer Vision (ECCV), 2024.</i>
<br />
<span style="margin-left:20px;">
[ <a href="https://link.springer.com/chapter/10.1007/978-3-031-72691-0_1">PDF</a> ] &nbsp;
[ <a href="https://arxiv.org/pdf/2407.04207" target="_blank">arXiv</a> ] &nbsp;
[ <a href="https://github.com/mainaksingha01/SpLIP" target="_blank">Code</a> ] &nbsp;
[ <a href="https://mainaksingha01.github.io/SpLIP/" target="_blank">Project</a> ] &nbsp;
[ <a href="https://link.springer.com/chapter/10.1007/978-3-031-72691-0_1" target="_blank">HTML</a> ] &nbsp;
[ <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:7d35ylLiE1EJ:scholar.google.com/&output=citation&scisdr=CrylxrZLELHTl_Wn954:ALhkC2QAAAAAaTKh757PFVg2S7b8xDsQ0lBJ3XQ&scisig=ALhkC2QAAAAAaTKh7yRKxj8OmphnrrOVs0TmJ6w&scisf=4&ct=citation&cd=-1&hl=en&scfhb=1" target="_blank">BibTeX</a> ]
</span>
</p>
</li>

<li>
<p>
<b>COSMo: CLIP Talks on Open-Set Multi-Target Domain Adaptation</b> <br />
Munish Monga, Sachin Kumar Giroh, Ankit Jha, <span style="color:#527bbd; font-weight:bold;">Mainak Singha</span>, Biplab Banerjee, Jocelyn Chanussot<br />
<i>British Machine Vision Conference (BMVC), 2024.</i>
<br />
<span style="margin-left:20px;">
[ <a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_31/paper.pdf" target="_blank">PDF</a> ] &nbsp;
[ <a href="https://arxiv.org/pdf/2409.00397" target="_blank">arXiv</a> ] &nbsp;
[ <a href="https://github.com/munish30monga/COSMo" target="_blank">Code</a> ] &nbsp;
[ <a href="https://bmvc2024.org/proceedings/31/" target="_blank">HTML</a> ] &nbsp;
[ <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:USDB0PyAelQJ:scholar.google.com/&output=citation&scisdr=CrylxrZLELHTl_Wv7HE:ALhkC2QAAAAAaTKp9HFe7PL10O4_kQC5O9WsK7U&scisig=ALhkC2QAAAAAaTKp9DG0C9ZLJYF8I_o8Ltz21ng&scisf=4&ct=citation&cd=-1&hl=en&scfhb=1" target="_blank">BibTeX</a> ] 
</span>
</p>
</li>


<li>
<p>
<b>Unknown Prompt, the only Lacuna: Unveiling CLIPâ€™s Potential for Open Domain Generalization</b> <br />
<span style="color:#527bbd; font-weight:bold;">Mainak Singha</span>, Ankit Jha, Shirsha Bose, Ashwin Nair, Moloud Abdar, Biplab Banerjee<br />
<i>Computer Vision and Pattern Recognition Conference (CVPR), 2024.</i>
<br />
<span style="margin-left:20px;">
[ <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Singha_Unknown_Prompt_the_only_Lacuna_Unveiling_CLIPs_Potential_for_Open_CVPR_2024_paper.pdf" target="_blank">PDF</a> ] &nbsp;
[ <a href="https://arxiv.org/pdf/2404.00710" target="_blank">arXiv</a> ] &nbsp;
[ <a href="https://github.com/mainaksingha01/ODG-CLIP" target="_blank">Code</a> ] &nbsp;
[ <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Singha_Unknown_Prompt_the_only_Lacuna_Unveiling_CLIPs_Potential_for_Open_CVPR_2024_paper.html" target="_blank">HTML</a> ] &nbsp;
[ <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:HS3-ueGbvZ0J:scholar.google.com/&output=citation&scisdr=CrylxrZLELHTl_Wijwo:ALhkC2QAAAAAaTKklwrkzf_I5i6rZ4YK3HZaUBw&scisig=ALhkC2QAAAAAaTKkl9luBsBvqD303jZMpg6bOaM&scisf=4&ct=citation&cd=-1&hl=en&scfhb=1" target="_blank">BibTeX</a> ] 
</span>
</p>
</li>


<li>
<p>
<b>CDAD-Net: Bridging Domain Gaps in Generalized Category Discovery</b> <br />
Sai Bhargav Rongali, Sarthak Mehrotra, Ankit Jha, Mohamad Hassan N C, Shirsha Bose, Tanisha Gupta, <span style="color:#527bbd; font-weight:bold;">Mainak Singha</span>, Biplab Banerjee<br />
<i>Computer Vision and Pattern Recognition Conference (CVPR) Workshops, 2024.</i>
<br />
<span style="margin-left:20px;">
[ <a href="https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/papers/Rongali_CDAD-Net_Bridging_Domain_Gaps_in_Generalized_Category_Discovery_CVPRW_2024_paper.pdf" target="_blank">PDF</a> ] &nbsp;
[ <a href="https://arxiv.org/pdf/2404.05366" target="_blank">arXiv</a> ] &nbsp;
[ <a href="https://github.com/SarthakM320/CDAD-Net" target="_blank">Code</a> ] &nbsp;
[ <a href="https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/html/Rongali_CDAD-Net_Bridging_Domain_Gaps_in_Generalized_Category_Discovery_CVPRW_2024_paper.html" target="_blank">HTML</a> ] &nbsp;
[ <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:x5e1vXoxJ8YJ:scholar.google.com/&output=citation&scisdr=CrylxrZLELHTl_WtOCA:ALhkC2QAAAAAaTKrICCsLH7XGj7SZUaOdI5jBG4&scisig=ALhkC2QAAAAAaTKrIO1e1Bfyp7u2drlOERjZzxg&scisf=4&ct=citation&cd=-1&hl=en&scfhb=1" target="_blank">BibTeX</a> ] 
</span>
</p>
</li>


<li>
<p>
<b>GraphVL: Graph-Enhanced Semantic Modeling via Vision-Language Models for Generalized Class Discovery</b> <br />
Bhupendra Solanki, Ashwin R Nair, <span style="color:#527bbd; font-weight:bold;">Mainak Singha</span>, Souradeep Mukhopadhyay, Ankit Jha, Biplab Banerjee<br />
<i>Indian Conference on Computer Vision Graphics and Image Processing (ICVGIP), 2024.</i>
<br />
<span style="margin-left:20px;">
[ <a href="https://dl.acm.org/doi/pdf/10.1145/3702250.3702266" target="_blank">PDF</a> ] &nbsp;
[ <a href="https://arxiv.org/pdf/2411.02074" target="_blank">arXiv</a> ] &nbsp;
[ <a href="https://dl.acm.org/doi/full/10.1145/3702250.3702266" target="_blank">HTML</a> ] &nbsp;
[ <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:1BKLn8GFgssJ:scholar.google.com/&output=citation&scisdr=CrylxrZLELHTl_Jxmwk:ALhkC2QAAAAAaTV3gwlsKKJOwD4DwV673OP9iPA&scisig=ALhkC2QAAAAAaTV3gzACJjQoGUl7ErdG2CzUPv8&scisf=4&ct=citation&cd=-1&hl=en&scfhb=1" target="_blank">BibTeX</a> ] 
</span>
</p>
</li>


<li>
<p>
<b>StyLIP: Multi-Scale Style-Conditioned Prompt Learning for CLIP-based Domain Generalization</b> <br />
Shirsha Bose, Ankit Jha, Enrico Fini, <span style="color:#527bbd; font-weight:bold;">Mainak Singha</span>, Biplab Banerjee, Elisa Ricci<br />
<i>Winter Conference on Applications of Computer Vision (WACV), 2024.</i>
<br />
<span style="margin-left:20px;">
[ <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Bose_STYLIP_Multi-Scale_Style-Conditioned_Prompt_Learning_for_CLIP-Based_Domain_Generalization_WACV_2024_paper.pdf" target="_blank">PDF</a> ] &nbsp;
[ <a href="https://arxiv.org/pdf/2302.09251" target="_blank">arXiv</a> ] &nbsp;
[ <a href="https://openaccess.thecvf.com/content/WACV2024/html/Bose_STYLIP_Multi-Scale_Style-Conditioned_Prompt_Learning_for_CLIP-Based_Domain_Generalization_WACV_2024_paper.html" target="_blank">HTML</a> ] &nbsp;
[ <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:XwHQHj9LtaEJ:scholar.google.com/&output=citation&scisdr=CrylxrZLELHTl_J-amY:ALhkC2QAAAAAaTV4cmZyGK5BnhiBvV2ZPfs48Ik&scisig=ALhkC2QAAAAAaTV4cgc-mknnF9bBquWXIOObAVs&scisf=4&ct=citation&cd=-1&hl=en&scfhb=1" target="_blank">BibTeX</a> ] 
</span>
</p>
</li>

</ol>


<h2>Journals <br /> <br /></h2>

<ol>

<li>
<p>
<b>Meta-Learning to Teach Semantic Prompts for Open Domain Generalization in Vision-Language Models</b> <br />
Shirsha Bose, <span style="color:#527bbd; font-weight:bold;">Mainak Singha</span>, Ankit Jha, Souradeep Mukhopadhyay, Biplab Banerjee <br />
<i>Transactions on Machine Learning Research (TMLR), 2025.</i>
<br />
<span style="margin-left:20px;">
[ <a href="https://openreview.net/pdf?id=uJELgNGiMW" target="_blank">PDF</a> ] &nbsp;
[ <a href="https://openreview.net/forum?id=uJELgNGiMW" target="_blank">HTML</a> ] &nbsp;
[ <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:4qmg90Pwi2EJ:scholar.google.com/&output=citation&scisdr=CrylxrZLELHTl_WkY0I:ALhkC2QAAAAAaTKie0LBjzhjDzPpKcaGPQMakCY&scisig=ALhkC2QAAAAAaTKie1jMfIDcfhpSRoj9dgJfK9M&scisf=4&ct=citation&cd=-1&hl=en" target="_blank">BibTeX</a> ]
</span>
</p>
</li>

</ol>
 
<div id="footer">
<div id="footer-text">
Page generated 2025-12-04 14:25:00 CET, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
<!-- This script will be injected in the pages of the site to collect visiting info fpr Google analytics.-->
<!-- Use your GoogleAnalytics ID, update the following code and the MY_ID with yours (used two times.)  -->
<script async src="https://www.googletagmanager.com/gtag/js?id=MY_ID"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'MY_ID');
</script>
</body>
</html>
